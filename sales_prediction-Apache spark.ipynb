{"cells":[{"cell_type":"code","source":["1+1"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# import necessary modules\nimport numpy as np\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import seaborn as sns\nsns.set(style = 'whitegrid', color_codes = True)\n\n\n#For statistical tests\nimport scipy.stats as st\n\n#For formula notation (similar to R)\nimport statsmodels.formula.api as smf\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.cross_validation import train_test_split\n\nimport operator"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["\n\n"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["dftrain = pd.read_csv(\"/dbfs/FileStore/tables/test.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql SELECT * FROM test_csv"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%sql SELECT * FROM items_csv"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["%sql select * from oil_csv o \ninner join test_csv t\non o.date  = t.date\nwhere o.dcoilwtico is null\n\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["\n%sql SELECT * from stores_csv s\ninner join test_csv t \non s.store_nbr = t.store_nbr"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["%sql SELECT * from stores_csv s \ninner join test_csv t \non s.store_nbr = t.store_nbr \ninner join items_csv i \non t.item_nbr =i.item_nbr\n"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["%sql SELECT  from stores_csv s \ninner join test_csv t \non s.store_nbr = t.store_nbr"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%sql select count(store_nbr),state \nfrom stores_csv \ngroup by state \n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["%sql select * from items_csv inner join test_csv \non items_csv.item_nbr  = test_csv.item_nbr\nwhere items_csv.family like 'B%'\nAND items_csv.perishable =1"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["%sql select * from stores_csv inner join test_csv \non stores_csv.store_nbr  = test_csv.store_nbr\nwhere stores_csv.state like 'C%'\nAND stores_csv.cluster >2\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["%sql select count(s.store_nbr),state from stores_csv s \ninner join test_csv t  \non s.store_nbr  = t.store_nbr group by state "],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["%sql select count(s.store_nbr),state \nfrom stores_csv s\ninner join test_csv t  \non s.store_nbr  = t.store_nbr \ngroup by state order by state"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["dfholidays = pd.read_csv(\"/dbfs/FileStore/tables/holidays_events.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["dftrain.head()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["dftrain.head()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["dfitems = pd.read_csv(\"/dbfs/FileStore/tables/items.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["dfitems.head()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["dftransactions = pd.read_csv(\"/dbfs/FileStore/tables/transactions.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["dfsample_submission = pd.read_csv(\"/dbfs/FileStore/tables/sample_submission.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["dfstores = pd.read_csv(\"/dbfs/FileStore/tables/stores.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["dfoil = pd.read_csv(\"/dbfs/FileStore/tables/oil.csv\", header=0)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["df_join = pd.merge(dftrain, dfstores, on= \"store_nbr\")\n\ndf_join.head()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["df_join = pd.merge(df_join, dfitems, on= \"item_nbr\")\n\ndf_join.head()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["df_join = pd.merge(df_join, dfholidays, on= \"date\")"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["df_join = pd.merge(df_join, dfoil, on= \"date\")\n\ndf_join.head()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["df_join['family'].unique()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["df_new =df_join"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["#dftr1 =dfjoin"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["#dftr2 =dfjoin"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["#dftr3 =dftr2"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["df_join.isnull().sum()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# df_join.onpromotion.replace({True:1,False:0},inplace =True)\n\ndf_join['class'].count()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["df_join['onpromotion'] = df_join['onpromotion'].replace(True,1)\ndf_join['onpromotion'] = df_join['onpromotion'].replace(False,0)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["dftr['onpromotion'] = dftr['onpromotion'].map({'True':'1' , 'False':0}) \n\ndf_new['onpromotion'] = df_new['onpromotion'].map({'True':'1' , 'False':0}) "],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["#dftr3.drop([dftr3.columns[4]], axis=1, inplace=True)\n\n"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["df_join['date'] =pd.to_datetime(df_join['date'],format =\"%Y-%m-%d\")"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["df_join['months'] = df_join['date'].apply(lambda x : x.month)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["df_join['year'] = df_join['date'].apply(lambda x : x.year)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["df_join['day'] = df_join['date'].apply(lambda x : x.day)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["df_join.drop('date', axis=1, inplace=True)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["df_join.head()"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["#######################################graphframes###############################"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["import graphframes \nfrom graphframes import *"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["localVertices = df_join[[\"item_nbr\",\"store_nbr\"]]\nv = sqlContext.createDataFrame(localVertices, [\"itemnum\",\"id\"])\ndisplay(v)"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["localEdges = df_join[[\"store_nbr\",\"state\",\"family\",\"cluster\"]]\ne = sqlContext.createDataFrame(localEdges, [\"src\", \"dst\", \"fam\",\"ftr\"])\ndisplay(e)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["g = GraphFrame(v, e)"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["display(g.vertices)"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["display(g.edges)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["display(g.inDegrees)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["display(g.outDegrees)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["inDeg = g.inDegrees\n#display(inDeg.orderBy(desc(\"inDegree\")).limit(25))\ndisplay(inDeg)"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["stores_filters = g.edges.filter(\"FTR = 12\").count()\nprint \"Number of stores for given cluster 12\",stores_filters"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["stores_filters = g.edges.filter(\"FTR = 1\").count()\nprint \"Number of stores for given cluster 11\",stores_filters"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["stores_filters = g.edges.filter(\"FTR = 8\").count()\nprint \"Number of stores for given cluster 8\",stores_filters"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["stores_filters = g.edges.filter(\"FTR = 5\").count()\nprint \"Number of stores for given cluster 5\",stores_filters"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["chel = g.edges.filter(\"dst = 'Pichincha'\")"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["Pichinchastores = chel.filter(\"FTR = 13\").count()"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["print \"Number of classes\",Pinchinchastores"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["val grap = Graph()"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":[" bikeStations = sqlContext.sql(\"SELECT * FROM test_csv\")"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["tripData = sqlContext.sql(\"SELECT * FROM stores_csv\")"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":["display(bikeStations)"],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"code","source":["display(tripData)"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":[" stationVertices = bikeStations\n  .withColumnRenamed(\"store_nbr\", \"id\")\n  \n\n  tripEdges = tripData\n  .withColumnRenamed(\"state\", \"src\")\n  .withColumnRenamed(\"type\", \"dst\")\n  .withColumnRenamed(\"cluster\", \"dst\")"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":[" stationGraph = GraphFrame( bikeStations, tripData)"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["df_join.head()"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["#########################ML ALGORITHMS##################################"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["X = df_join[['store_nbr','state','type_x','class']]\ny = df_join[['cluster']]"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["X.head()"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["y.head()"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n\n#data, labels = np.arange(10).reshape((5, 2)), range(5)\n\nx_train, x_test,y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"code","source":["len(y_train)"],"metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":["len(x_test)"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import MultinomialNB\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn import linear_model"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":89},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"code","source":["df_join['class'].unique()"],"metadata":{},"outputs":[],"execution_count":91},{"cell_type":"code","source":["xv=x_train"],"metadata":{},"outputs":[],"execution_count":92},{"cell_type":"code","source":["xv.head()"],"metadata":{},"outputs":[],"execution_count":93},{"cell_type":"code","source":["\nnew=[]\n\nfor value in xv[\"state\"]:\n    if value == 'Pichincha':\n        new.append(1)\n    elif value == 'Guayas':\n        new.append('2')\n    elif value == 'Azuay':\n        new.append('3')\n    elif value == 'Tungurahua':\n        new.append('4')\n    elif value == 'Santo Domingo de los Tsachilas':\n        new.append('5')\n    elif value == 'Pastaza':\n        new.append('6')\n    elif value == 'Manabi':\n        new.append('7')\n    elif value == 'Esmeraldas':\n        new.append('8')\n    elif value == 'Chimborazo':\n        new.append('9')\n    elif value == 'Los Rios':\n        new.append('10')\n    elif value == 'El Oro':\n        new.append('11')\n    else: new.append('12')\n \n        \nxv['nwstate']=new "],"metadata":{},"outputs":[],"execution_count":94},{"cell_type":"code","source":["xv.head()"],"metadata":{},"outputs":[],"execution_count":95},{"cell_type":"code","source":["\nnew1=[]\n\nfor value in xv[\"type_x\"]:\n    if value == 'D':\n        new1.append(4)\n    elif value == 'C':\n        new1.append(3)\n    elif value == 'B':\n        new1.append(2)\n   \n \n   \n\n    else: new1.append(1)\n \n        \nxv[\"NW\"]=new1 "],"metadata":{},"outputs":[],"execution_count":96},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":97},{"cell_type":"code","source":["x_train.head()"],"metadata":{},"outputs":[],"execution_count":98},{"cell_type":"code","source":["x_train = x_train.drop(['type_x'], axis=1)"],"metadata":{},"outputs":[],"execution_count":99},{"cell_type":"code","source":["x_train = x_train.drop(['state'], axis=1)"],"metadata":{},"outputs":[],"execution_count":100},{"cell_type":"code","source":["x_train.head()"],"metadata":{},"outputs":[],"execution_count":101},{"cell_type":"code","source":["xt =x_test.copy()"],"metadata":{},"outputs":[],"execution_count":102},{"cell_type":"code","source":["clf = [MultinomialNB(), SVC(kernel = 'linear', C=1.5, probability=True), LogisticRegression()]\n\nlabels = [ 'Naive Bayes', 'SVM', 'Log regres']\n\nmean_scores = []\nmean_scores_2 = []\ncms = []\n\nfor i in range(0,2):\n\n    clf[i].fit(x_train,y_train)\n   # clf[i].fit(X_train_2,y_train)\n\n    scores = cross_val_score(clf[i], x_train, y_train, cv=10)\n  #  scores_2 = cross_val_score(clf[i], X_train_2, y_train, cv=10)\n    print (labels[i],\" : \", scores.mean(), \" : \")\n    \n    mean_scores.append(scores.mean())  \n    #mean_scores_2.append(scores_2.mean())"],"metadata":{},"outputs":[],"execution_count":103},{"cell_type":"code","source":["clf1 = SVC(kernel = 'linear', C=1.5, probability=True)\n\nlabels = [ 'Naive Bayes', 'SVM', 'Log regres']\n\nmean_scores = []\nmean_scores_2 = []\ncms = []\n\n#for i in range(0,3):\nmodel = clf1.fit(x_train,y_train)\n# clf[i].fit(X_train_2,y_train)\n\n#scores = cross_val_score(clf1, x_train, y_train)\n  #  scores_2 = cross_val_score(clf[i], X_train_2, y_train, cv=10)\n#print (labels[0],\" : \", scores.mean(), \" : \")\n    \n#mean_scores.append(scores.mean())  \n    #mean_scores_2.append(scores_2.mean())\n  \nmodel.score(x_train,y_train)"],"metadata":{},"outputs":[],"execution_count":104},{"cell_type":"code","source":["clf1 = MultinomialNB()\n\nlabels = [ 'Naive Bayes', 'SVM', 'Log regres']\n\nmean_scores = []\nmean_scores_2 = []\ncms = []\n\n#for i in range(0,3):\nmodel = clf1.fit(x_train,y_train)\n# clf[i].fit(X_train_2,y_train)\n\n#scores = cross_val_score(clf1, x_train, y_train)\n  #  scores_2 = cross_val_score(clf[i], X_train_2, y_train, cv=10)\n#print (labels[0],\" : \", scores.mean(), \" : \")\n    \n#mean_scores.append(scores.mean())  \n    #mean_scores_2.append(scores_2.mean())\n  \nmodel.score(x_train,y_train)"],"metadata":{},"outputs":[],"execution_count":105},{"cell_type":"code","source":["clf1 =LogisticRegression()\n\nlabels = [ 'Naive Bayes', 'SVM', 'Log regres']\n\nmean_scores = []\nmean_scores_2 = []\ncms = []\n\n#for i in range(0,3):\nmodel = clf1.fit(x_train,y_train)\n# clf[i].fit(X_train_2,y_train)\n\n#scores = cross_val_score(clf1, x_train, y_train)\n  #  scores_2 = cross_val_score(clf[i], X_train_2, y_train, cv=10)\n#print (labels[0],\" : \", scores.mean(), \" : \")\n    \n#mean_scores.append(scores.mean())  \n    #mean_scores_2.append(scores_2.mean())\n  \nmodel.score(x_train,y_train)"],"metadata":{},"outputs":[],"execution_count":106},{"cell_type":"code","source":["type(x_train)\n"],"metadata":{},"outputs":[],"execution_count":107},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\n"],"metadata":{},"outputs":[],"execution_count":108},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":109},{"cell_type":"code","source":["dfj = df_join.copy()"],"metadata":{},"outputs":[],"execution_count":110},{"cell_type":"code","source":["from pyspark.ml import Pipeline"],"metadata":{},"outputs":[],"execution_count":111},{"cell_type":"code","source":["dataset = spark.table(\"stores_csv\")"],"metadata":{},"outputs":[],"execution_count":112},{"cell_type":"code","source":[" "],"metadata":{},"outputs":[],"execution_count":113},{"cell_type":"code","source":["###One-Hot Encoding\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = [\"store_nbr\",\"city\", \"state\", \"type\",\"cluster\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":114},{"cell_type":"code","source":["# Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"type\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":115},{"cell_type":"code","source":["assemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns)\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":116},{"cell_type":"code","source":["# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(dataset)\ndataset = pipelineModel.transform(dataset)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ndataset = dataset.select(selectedcols)\ndisplay(dataset)"],"metadata":{},"outputs":[],"execution_count":117},{"cell_type":"code","source":["### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":118},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":119},{"cell_type":"code","source":["# Make predictions on test data using the transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":120},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":121},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\n# You can select any columns in the above schema to view as well. For example's sake we will choose age & occupation\nselected = predictions.select(\"label\", \"prediction\", \"probability\", \"cluster\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":122},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":123}],"metadata":{"name":"proj1","notebookId":2058122549118572},"nbformat":4,"nbformat_minor":0}
